{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-04 22:04:56,945\tWARNING worker.py:1373 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Perhaps you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-49d2a05a4083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_cpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/ray/worker.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(redis_address, num_cpus, num_gpus, resources, object_store_memory, redis_max_memory, log_to_driver, node_ip_address, object_id_seed, local_mode, redirect_worker_output, redirect_output, ignore_reinit_error, num_redis_shards, redis_max_clients, redis_password, plasma_directory, huge_pages, include_webui, job_id, configure_logging, logging_level, logging_format, plasma_store_socket_name, raylet_socket_name, temp_dir, load_code_from_local, _internal_config)\u001b[0m\n\u001b[1;32m   1381\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m             raise Exception(\"Perhaps you called ray.init twice by accident? \"\n\u001b[0m\u001b[1;32m   1384\u001b[0m                             \u001b[0;34m\"This error can be suppressed by passing in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                             \u001b[0;34m\"'ignore_reinit_error=True' or by calling \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Perhaps you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'."
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import gym\n",
    "import numpy as np\n",
    "import psutil\n",
    "import scipy.signal\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "\n",
    "ray.init(num_cpus=num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 2.43 s, total: 3.69 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_tasks = 12\n",
    "\n",
    "@ray.remote\n",
    "def f(image, random_filter):\n",
    "    # Do some image processing.\n",
    "    return scipy.signal.convolve2d(image, random_filter)[::5, ::5]\n",
    "\n",
    "filters = [np.random.normal(size=(4, 4)) for _ in range(num_tasks)]\n",
    "\n",
    "# Time the code below.\n",
    "def test():\n",
    "    for _ in range(10):\n",
    "        image = np.zeros((3000, 3000))\n",
    "        image_id = ray.put(image)\n",
    "        ray.get([f.remote(image_id, filters[i]) for i in range(num_tasks)])\n",
    "        \n",
    "%time test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.37 s, sys: 9.47 s, total: 17.8 s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import psutil\n",
    "import scipy.signal\n",
    "\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "\n",
    "def f(args):\n",
    "    image, random_filter = args\n",
    "    # Do some image processing.\n",
    "    return scipy.signal.convolve2d(image, random_filter)[::5, ::5]\n",
    "\n",
    "pool = Pool(num_cpus)\n",
    "\n",
    "filters = [np.random.normal(size=(4, 4)) for _ in range(num_tasks)]\n",
    "\n",
    "# Time the code below.\n",
    "\n",
    "def test():\n",
    "    for _ in range(10):\n",
    "        image = np.zeros((3000, 3000))\n",
    "        pool.map(f, zip(num_tasks * [image], filters))\n",
    "%time test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=15455, shape=(10, 5), dtype=float64, numpy=\n",
       "array([[ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811],\n",
       "       [ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811],\n",
       "       [ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811],\n",
       "       [ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811],\n",
       "       [ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811],\n",
       "       [ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811],\n",
       "       [ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811],\n",
       "       [ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811],\n",
       "       [ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811],\n",
       "       [ 0.05062235,  0.14818228, -0.32560839,  0.41634638, -0.04870811]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D,Bidirectional, LSTM, Dropout\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "class MLP(Model):\n",
    "    def __init__(self, LAYER_SIZE, OUTPUT_SIZE):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.d1 = Dense(LAYER_SIZE, activation='relu')\n",
    "        self.d2 = Dense(LAYER_SIZE, activation='relu')\n",
    "        self.d3 = Dense(OUTPUT_SIZE, activation = 'tanh')\n",
    "\n",
    "    def call(self, x, acts=None, training=False):\n",
    "        \n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.d3(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(12, 5)\n",
    "model2 = MLP(13,4)\n",
    "model(np.ones([10,12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Person:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "    \n",
    "  def test(self,weight):\n",
    "        return weight.shape\n",
    "    \n",
    "  def ez(self):\n",
    "        return 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actor = Person.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(actor.test.remote(model.trainable_variables[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-04 18:03:28,762\tWARNING worker.py:352 -- WARNING: Falling back to serializing objects of type <enum 'VariableSynchronization'> by using pickle. This may be inefficient.\n",
      "2019-09-04 18:03:28,775\tWARNING worker.py:352 -- WARNING: Falling back to serializing objects of type <enum 'VariableAggregation'> by using pickle. This may be inefficient.\n"
     ]
    }
   ],
   "source": [
    "ray.get(actor.test.remote(model.trainable_variables[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(12, 12) dtype=float64, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.assign(model.trainable_variables[0], np.ones((12,12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([[-1.42202652e-01,  3.47808911e-01,  9.59553275e-02,\n",
       "          1.66138875e-01, -5.82863090e-03, -4.29771430e-01,\n",
       "          3.76412865e-01,  1.05054466e-02,  2.65030418e-01,\n",
       "          1.19525392e-01, -3.56003166e-01, -3.52443089e-01],\n",
       "        [ 2.26245708e-01,  1.53541256e-01,  2.32678078e-01,\n",
       "          4.33518223e-01, -2.23838353e-01, -6.23411892e-02,\n",
       "          1.79863947e-01,  3.11978411e-01,  4.90130119e-01,\n",
       "         -4.54059359e-01,  4.84324657e-01,  5.80782562e-02],\n",
       "        [ 3.66083005e-01, -1.24247130e-01,  1.70881751e-01,\n",
       "          2.05461150e-01, -7.40595220e-02, -3.81633274e-01,\n",
       "          2.08729053e-01,  3.89264905e-01, -1.93649683e-02,\n",
       "         -1.93253272e-01, -2.17096384e-01,  4.23549277e-01],\n",
       "        [ 2.01936148e-01,  1.50677334e-01, -8.77559244e-02,\n",
       "          4.93268602e-02,  4.69718408e-02,  4.19968435e-01,\n",
       "          3.88331372e-01,  1.99307677e-01, -2.02643428e-01,\n",
       "          5.27030050e-02,  1.39601180e-01,  1.57921977e-01],\n",
       "        [-3.20394260e-01, -1.31325556e-01,  1.85816985e-01,\n",
       "         -1.85182350e-02,  2.25024109e-01, -3.45609857e-01,\n",
       "         -2.67502299e-01, -4.78094152e-01,  1.06224685e-01,\n",
       "         -4.23216328e-01, -4.66235026e-01, -6.68038559e-02],\n",
       "        [ 3.86866354e-01, -1.94724549e-02,  1.88559818e-01,\n",
       "          1.70705568e-02,  1.34607711e-01,  2.04120379e-01,\n",
       "         -1.56313223e-01, -1.15147124e-01,  4.21933660e-01,\n",
       "          4.15238488e-01, -3.61004144e-01, -1.46121080e-01],\n",
       "        [-1.73769595e-01, -2.75396031e-02,  1.58991116e-01,\n",
       "         -1.40250702e-01, -4.78720671e-01,  2.72127240e-01,\n",
       "          1.88318658e-01, -2.54424179e-01, -2.38341015e-02,\n",
       "         -3.72746550e-01, -4.12118786e-01, -4.50083863e-01],\n",
       "        [ 1.03477949e-01, -4.99265468e-01, -3.44709908e-01,\n",
       "         -4.62695540e-01, -1.04079336e-01,  3.08480188e-02,\n",
       "          3.78063829e-01,  6.93934006e-03, -4.78943662e-01,\n",
       "         -1.41959409e-01, -1.19333706e-01,  3.08804594e-01],\n",
       "        [-3.10482708e-01,  7.31659482e-02,  1.01411303e-01,\n",
       "         -1.09117963e-01, -4.59708512e-01,  4.37443367e-01,\n",
       "         -1.24667479e-01,  6.92044546e-02, -2.48399234e-01,\n",
       "         -4.66190482e-02,  1.20258076e-01,  1.29122729e-01],\n",
       "        [ 4.55071388e-01, -4.83291965e-02,  1.95838056e-01,\n",
       "          4.38884183e-01,  2.44727310e-02,  2.54502585e-01,\n",
       "          1.45322907e-01,  3.70065715e-01,  1.13614688e-01,\n",
       "         -4.52933970e-01, -3.63861124e-01, -4.09745655e-01],\n",
       "        [ 2.56054501e-01, -8.95642493e-02,  1.29726343e-01,\n",
       "          1.50712734e-01, -3.14944392e-01,  2.03385953e-02,\n",
       "         -1.16040589e-01, -1.56676473e-01, -1.71396089e-01,\n",
       "         -9.30191110e-02,  4.24737440e-02, -5.82949523e-02],\n",
       "        [-1.14224768e-01, -4.10009241e-01,  3.21669296e-01,\n",
       "         -3.53669608e-02,  1.59588791e-01,  1.94312122e-06,\n",
       "         -4.88364957e-01,  1.28507569e-01, -1.08280416e-01,\n",
       "          7.11121244e-02,  4.82465877e-01, -4.59777961e-01]]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([[ 0.06211771,  0.24966451, -0.01384237,  0.29369079,  0.34847106],\n",
       "        [-0.13295887, -0.25428574, -0.2364476 ,  0.28675198, -0.51559414],\n",
       "        [-0.5098628 , -0.38208599,  0.58475659, -0.44271429,  0.30056212],\n",
       "        [-0.34749573,  0.4529608 , -0.22908164,  0.03541686,  0.07675425],\n",
       "        [ 0.32233636,  0.3106129 ,  0.06146236,  0.19909685, -0.34352236],\n",
       "        [-0.24038357,  0.16164147, -0.15644609,  0.54084766, -0.22659195],\n",
       "        [-0.28698525, -0.28273317,  0.48396617,  0.16013297, -0.05440218],\n",
       "        [ 0.16236665, -0.28364672,  0.1025368 ,  0.2282006 ,  0.166199  ],\n",
       "        [-0.21703716, -0.26668283,  0.18739874, -0.00622303, -0.17755259],\n",
       "        [-0.15040402,  0.55648705, -0.15365776, -0.35344297, -0.57115752],\n",
       "        [ 0.09626045, -0.00530424, -0.2144136 ,  0.34795718,  0.22773678],\n",
       "        [ 0.30770702,  0.4671781 , -0.33072523,  0.23828401,  0.42753808]]),\n",
       " array([0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.numpy() for n in model.trainable_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "x.append([n.numpy() for n in model.trainable_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=146, shape=(12, 12), dtype=float64, numpy=\n",
       "array([[3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables[0]+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'mlp/dense/kernel:0' shape=(12, 12) dtype=float64, numpy=\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])>,\n",
       " <tf.Variable 'mlp/dense/bias:0' shape=(12,) dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " <tf.Variable 'mlp/dense_1/kernel:0' shape=(12, 12) dtype=float64, numpy=\n",
       " array([[-1.42202652e-01,  3.47808911e-01,  9.59553275e-02,\n",
       "          1.66138875e-01, -5.82863090e-03, -4.29771430e-01,\n",
       "          3.76412865e-01,  1.05054466e-02,  2.65030418e-01,\n",
       "          1.19525392e-01, -3.56003166e-01, -3.52443089e-01],\n",
       "        [ 2.26245708e-01,  1.53541256e-01,  2.32678078e-01,\n",
       "          4.33518223e-01, -2.23838353e-01, -6.23411892e-02,\n",
       "          1.79863947e-01,  3.11978411e-01,  4.90130119e-01,\n",
       "         -4.54059359e-01,  4.84324657e-01,  5.80782562e-02],\n",
       "        [ 3.66083005e-01, -1.24247130e-01,  1.70881751e-01,\n",
       "          2.05461150e-01, -7.40595220e-02, -3.81633274e-01,\n",
       "          2.08729053e-01,  3.89264905e-01, -1.93649683e-02,\n",
       "         -1.93253272e-01, -2.17096384e-01,  4.23549277e-01],\n",
       "        [ 2.01936148e-01,  1.50677334e-01, -8.77559244e-02,\n",
       "          4.93268602e-02,  4.69718408e-02,  4.19968435e-01,\n",
       "          3.88331372e-01,  1.99307677e-01, -2.02643428e-01,\n",
       "          5.27030050e-02,  1.39601180e-01,  1.57921977e-01],\n",
       "        [-3.20394260e-01, -1.31325556e-01,  1.85816985e-01,\n",
       "         -1.85182350e-02,  2.25024109e-01, -3.45609857e-01,\n",
       "         -2.67502299e-01, -4.78094152e-01,  1.06224685e-01,\n",
       "         -4.23216328e-01, -4.66235026e-01, -6.68038559e-02],\n",
       "        [ 3.86866354e-01, -1.94724549e-02,  1.88559818e-01,\n",
       "          1.70705568e-02,  1.34607711e-01,  2.04120379e-01,\n",
       "         -1.56313223e-01, -1.15147124e-01,  4.21933660e-01,\n",
       "          4.15238488e-01, -3.61004144e-01, -1.46121080e-01],\n",
       "        [-1.73769595e-01, -2.75396031e-02,  1.58991116e-01,\n",
       "         -1.40250702e-01, -4.78720671e-01,  2.72127240e-01,\n",
       "          1.88318658e-01, -2.54424179e-01, -2.38341015e-02,\n",
       "         -3.72746550e-01, -4.12118786e-01, -4.50083863e-01],\n",
       "        [ 1.03477949e-01, -4.99265468e-01, -3.44709908e-01,\n",
       "         -4.62695540e-01, -1.04079336e-01,  3.08480188e-02,\n",
       "          3.78063829e-01,  6.93934006e-03, -4.78943662e-01,\n",
       "         -1.41959409e-01, -1.19333706e-01,  3.08804594e-01],\n",
       "        [-3.10482708e-01,  7.31659482e-02,  1.01411303e-01,\n",
       "         -1.09117963e-01, -4.59708512e-01,  4.37443367e-01,\n",
       "         -1.24667479e-01,  6.92044546e-02, -2.48399234e-01,\n",
       "         -4.66190482e-02,  1.20258076e-01,  1.29122729e-01],\n",
       "        [ 4.55071388e-01, -4.83291965e-02,  1.95838056e-01,\n",
       "          4.38884183e-01,  2.44727310e-02,  2.54502585e-01,\n",
       "          1.45322907e-01,  3.70065715e-01,  1.13614688e-01,\n",
       "         -4.52933970e-01, -3.63861124e-01, -4.09745655e-01],\n",
       "        [ 2.56054501e-01, -8.95642493e-02,  1.29726343e-01,\n",
       "          1.50712734e-01, -3.14944392e-01,  2.03385953e-02,\n",
       "         -1.16040589e-01, -1.56676473e-01, -1.71396089e-01,\n",
       "         -9.30191110e-02,  4.24737440e-02, -5.82949523e-02],\n",
       "        [-1.14224768e-01, -4.10009241e-01,  3.21669296e-01,\n",
       "         -3.53669608e-02,  1.59588791e-01,  1.94312122e-06,\n",
       "         -4.88364957e-01,  1.28507569e-01, -1.08280416e-01,\n",
       "          7.11121244e-02,  4.82465877e-01, -4.59777961e-01]])>,\n",
       " <tf.Variable 'mlp/dense_1/bias:0' shape=(12,) dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " <tf.Variable 'mlp/dense_2/kernel:0' shape=(12, 5) dtype=float64, numpy=\n",
       " array([[ 0.06211771,  0.24966451, -0.01384237,  0.29369079,  0.34847106],\n",
       "        [-0.13295887, -0.25428574, -0.2364476 ,  0.28675198, -0.51559414],\n",
       "        [-0.5098628 , -0.38208599,  0.58475659, -0.44271429,  0.30056212],\n",
       "        [-0.34749573,  0.4529608 , -0.22908164,  0.03541686,  0.07675425],\n",
       "        [ 0.32233636,  0.3106129 ,  0.06146236,  0.19909685, -0.34352236],\n",
       "        [-0.24038357,  0.16164147, -0.15644609,  0.54084766, -0.22659195],\n",
       "        [-0.28698525, -0.28273317,  0.48396617,  0.16013297, -0.05440218],\n",
       "        [ 0.16236665, -0.28364672,  0.1025368 ,  0.2282006 ,  0.166199  ],\n",
       "        [-0.21703716, -0.26668283,  0.18739874, -0.00622303, -0.17755259],\n",
       "        [-0.15040402,  0.55648705, -0.15365776, -0.35344297, -0.57115752],\n",
       "        [ 0.09626045, -0.00530424, -0.2144136 ,  0.34795718,  0.22773678],\n",
       "        [ 0.30770702,  0.4671781 , -0.33072523,  0.23828401,  0.42753808]])>,\n",
       " <tf.Variable 'mlp/dense_2/bias:0' shape=(5,) dtype=float64, numpy=array([0., 0., 0., 0., 0.])>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = model.trainable_variables\n",
    "y = [i+1 for i in model.trainable_variables]\n",
    "z = [i-1 for i in model.trainable_variables]\n",
    "\n",
    "\n",
    "x2 = model2.trainable_variables\n",
    "y2 = [i+1 for i in model2.trainable_variables]\n",
    "z2 = [i-1 for i in model2.trainable_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [[x,x2], [y,y2], [z,z2]]\n",
    "by_models = zip(*weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c')\n",
      "(2, 3, 8)\n"
     ]
    }
   ],
   "source": [
    "weights = [['a',2], ['b',3], ['c',8]]\n",
    "for q in zip(*weights):\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=14884, shape=(12, 12), dtype=float64, numpy=\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])>,\n",
       " <tf.Tensor: id=14887, shape=(12,), dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " <tf.Tensor: id=14890, shape=(12, 12), dtype=float64, numpy=\n",
       " array([[-1.42202652e-01,  3.47808911e-01,  9.59553275e-02,\n",
       "          1.66138875e-01, -5.82863090e-03, -4.29771430e-01,\n",
       "          3.76412865e-01,  1.05054466e-02,  2.65030418e-01,\n",
       "          1.19525392e-01, -3.56003166e-01, -3.52443089e-01],\n",
       "        [ 2.26245708e-01,  1.53541256e-01,  2.32678078e-01,\n",
       "          4.33518223e-01, -2.23838353e-01, -6.23411892e-02,\n",
       "          1.79863947e-01,  3.11978411e-01,  4.90130119e-01,\n",
       "         -4.54059359e-01,  4.84324657e-01,  5.80782562e-02],\n",
       "        [ 3.66083005e-01, -1.24247130e-01,  1.70881751e-01,\n",
       "          2.05461150e-01, -7.40595220e-02, -3.81633274e-01,\n",
       "          2.08729053e-01,  3.89264905e-01, -1.93649683e-02,\n",
       "         -1.93253272e-01, -2.17096384e-01,  4.23549277e-01],\n",
       "        [ 2.01936148e-01,  1.50677334e-01, -8.77559244e-02,\n",
       "          4.93268602e-02,  4.69718408e-02,  4.19968435e-01,\n",
       "          3.88331372e-01,  1.99307677e-01, -2.02643428e-01,\n",
       "          5.27030050e-02,  1.39601180e-01,  1.57921977e-01],\n",
       "        [-3.20394260e-01, -1.31325556e-01,  1.85816985e-01,\n",
       "         -1.85182350e-02,  2.25024109e-01, -3.45609857e-01,\n",
       "         -2.67502299e-01, -4.78094152e-01,  1.06224685e-01,\n",
       "         -4.23216328e-01, -4.66235026e-01, -6.68038559e-02],\n",
       "        [ 3.86866354e-01, -1.94724549e-02,  1.88559818e-01,\n",
       "          1.70705568e-02,  1.34607711e-01,  2.04120379e-01,\n",
       "         -1.56313223e-01, -1.15147124e-01,  4.21933660e-01,\n",
       "          4.15238488e-01, -3.61004144e-01, -1.46121080e-01],\n",
       "        [-1.73769595e-01, -2.75396031e-02,  1.58991116e-01,\n",
       "         -1.40250702e-01, -4.78720671e-01,  2.72127240e-01,\n",
       "          1.88318658e-01, -2.54424179e-01, -2.38341015e-02,\n",
       "         -3.72746550e-01, -4.12118786e-01, -4.50083863e-01],\n",
       "        [ 1.03477949e-01, -4.99265468e-01, -3.44709908e-01,\n",
       "         -4.62695540e-01, -1.04079336e-01,  3.08480188e-02,\n",
       "          3.78063829e-01,  6.93934006e-03, -4.78943662e-01,\n",
       "         -1.41959409e-01, -1.19333706e-01,  3.08804594e-01],\n",
       "        [-3.10482708e-01,  7.31659482e-02,  1.01411303e-01,\n",
       "         -1.09117963e-01, -4.59708512e-01,  4.37443367e-01,\n",
       "         -1.24667479e-01,  6.92044546e-02, -2.48399234e-01,\n",
       "         -4.66190482e-02,  1.20258076e-01,  1.29122729e-01],\n",
       "        [ 4.55071388e-01, -4.83291965e-02,  1.95838056e-01,\n",
       "          4.38884183e-01,  2.44727310e-02,  2.54502585e-01,\n",
       "          1.45322907e-01,  3.70065715e-01,  1.13614688e-01,\n",
       "         -4.52933970e-01, -3.63861124e-01, -4.09745655e-01],\n",
       "        [ 2.56054501e-01, -8.95642493e-02,  1.29726343e-01,\n",
       "          1.50712734e-01, -3.14944392e-01,  2.03385953e-02,\n",
       "         -1.16040589e-01, -1.56676473e-01, -1.71396089e-01,\n",
       "         -9.30191110e-02,  4.24737440e-02, -5.82949523e-02],\n",
       "        [-1.14224768e-01, -4.10009241e-01,  3.21669296e-01,\n",
       "         -3.53669608e-02,  1.59588791e-01,  1.94312122e-06,\n",
       "         -4.88364957e-01,  1.28507569e-01, -1.08280416e-01,\n",
       "          7.11121244e-02,  4.82465877e-01, -4.59777961e-01]])>,\n",
       " <tf.Tensor: id=14893, shape=(12,), dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " <tf.Tensor: id=14896, shape=(12, 5), dtype=float64, numpy=\n",
       " array([[ 0.06211771,  0.24966451, -0.01384237,  0.29369079,  0.34847106],\n",
       "        [-0.13295887, -0.25428574, -0.2364476 ,  0.28675198, -0.51559414],\n",
       "        [-0.5098628 , -0.38208599,  0.58475659, -0.44271429,  0.30056212],\n",
       "        [-0.34749573,  0.4529608 , -0.22908164,  0.03541686,  0.07675425],\n",
       "        [ 0.32233636,  0.3106129 ,  0.06146236,  0.19909685, -0.34352236],\n",
       "        [-0.24038357,  0.16164147, -0.15644609,  0.54084766, -0.22659195],\n",
       "        [-0.28698525, -0.28273317,  0.48396617,  0.16013297, -0.05440218],\n",
       "        [ 0.16236665, -0.28364672,  0.1025368 ,  0.2282006 ,  0.166199  ],\n",
       "        [-0.21703716, -0.26668283,  0.18739874, -0.00622303, -0.17755259],\n",
       "        [-0.15040402,  0.55648705, -0.15365776, -0.35344297, -0.57115752],\n",
       "        [ 0.09626045, -0.00530424, -0.2144136 ,  0.34795718,  0.22773678],\n",
       "        [ 0.30770702,  0.4671781 , -0.33072523,  0.23828401,  0.42753808]])>,\n",
       " <tf.Tensor: id=14899, shape=(5,), dtype=float64, numpy=array([0., 0., 0., 0., 0.])>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[np.sum(w)/len(w) for w in zip(*[x])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 5}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'ok':5}\n",
    "d.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.3973526 ,  0.23372644, -0.16991816, -0.47508506,\n",
       "         -0.25340132, -0.31434749,  0.36006794, -0.28112358,\n",
       "          0.00555293,  0.20267567,  0.14065435,  0.04354843],\n",
       "        [-0.38942335,  0.46742368,  0.46361934,  0.22871681,\n",
       "          0.14772727,  0.29518396,  0.16449136,  0.10679124,\n",
       "          0.0120779 , -0.06643967, -0.25144239, -0.08196039],\n",
       "        [ 0.42249216, -0.25546421,  0.16359994, -0.29694118,\n",
       "         -0.12504064, -0.37510743, -0.26868091, -0.35480439,\n",
       "          0.10558946,  0.07322366,  0.04522533, -0.17068743],\n",
       "        [-0.42908809,  0.40899685, -0.1491241 , -0.07867091,\n",
       "         -0.23094486,  0.20849508, -0.21904857, -0.20920019,\n",
       "          0.44698554,  0.2427562 , -0.33457385, -0.28715636],\n",
       "        [ 0.49086107, -0.42783939,  0.27332596, -0.47542985,\n",
       "          0.32009296, -0.24447311, -0.19043995, -0.11937856,\n",
       "         -0.05637138,  0.08062986,  0.25294316,  0.13309879],\n",
       "        [ 0.4787761 ,  0.30332286,  0.24253408, -0.09815372,\n",
       "          0.05138952,  0.19375302,  0.02051598, -0.14094366,\n",
       "          0.41507727,  0.38249604, -0.32730239, -0.27479612],\n",
       "        [-0.16261284, -0.43784039, -0.08655541, -0.35141899,\n",
       "         -0.45983181, -0.40996616,  0.08778094, -0.49655587,\n",
       "          0.07393023, -0.2193091 ,  0.38961471, -0.11188456],\n",
       "        [ 0.26097053,  0.02488847,  0.01165564, -0.20947074,\n",
       "          0.47680115, -0.08586257, -0.350878  , -0.21711959,\n",
       "          0.06797958,  0.42209209, -0.45038151,  0.39356278],\n",
       "        [-0.43955929, -0.19956568,  0.17475514,  0.42311993,\n",
       "          0.03074791,  0.28869675, -0.38528544, -0.46151628,\n",
       "         -0.07851592, -0.07114387,  0.42453619,  0.22133687],\n",
       "        [-0.21902152,  0.02936901,  0.47123554, -0.26473803,\n",
       "         -0.19817043,  0.01288764, -0.40774599,  0.49407679,\n",
       "          0.29313609,  0.09291089,  0.355516  ,  0.48405895],\n",
       "        [ 0.37918922,  0.39427059,  0.18631852, -0.3537988 ,\n",
       "         -0.37502982, -0.45477822, -0.00354354, -0.24523505,\n",
       "         -0.4009292 ,  0.30712128,  0.04661893,  0.42495661],\n",
       "        [-0.0529117 ,  0.22796392, -0.34951371, -0.3840651 ,\n",
       "          0.37434945, -0.29603787, -0.12061184, -0.32186205,\n",
       "         -0.35968408,  0.01075786, -0.36485249, -0.04711448]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((np.expand_dims(x[0].numpy(), 0),), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=13398, shape=(12, 12), dtype=float64, numpy=\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])>,\n",
       " <tf.Tensor: id=13403, shape=(12,), dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " <tf.Tensor: id=13408, shape=(12, 12), dtype=float64, numpy=\n",
       " array([[-1.42202652e-01,  3.47808911e-01,  9.59553275e-02,\n",
       "          1.66138875e-01, -5.82863090e-03, -4.29771430e-01,\n",
       "          3.76412865e-01,  1.05054466e-02,  2.65030418e-01,\n",
       "          1.19525392e-01, -3.56003166e-01, -3.52443089e-01],\n",
       "        [ 2.26245708e-01,  1.53541256e-01,  2.32678078e-01,\n",
       "          4.33518223e-01, -2.23838353e-01, -6.23411892e-02,\n",
       "          1.79863947e-01,  3.11978411e-01,  4.90130119e-01,\n",
       "         -4.54059359e-01,  4.84324657e-01,  5.80782562e-02],\n",
       "        [ 3.66083005e-01, -1.24247130e-01,  1.70881751e-01,\n",
       "          2.05461150e-01, -7.40595220e-02, -3.81633274e-01,\n",
       "          2.08729053e-01,  3.89264905e-01, -1.93649683e-02,\n",
       "         -1.93253272e-01, -2.17096384e-01,  4.23549277e-01],\n",
       "        [ 2.01936148e-01,  1.50677334e-01, -8.77559244e-02,\n",
       "          4.93268602e-02,  4.69718408e-02,  4.19968435e-01,\n",
       "          3.88331372e-01,  1.99307677e-01, -2.02643428e-01,\n",
       "          5.27030050e-02,  1.39601180e-01,  1.57921977e-01],\n",
       "        [-3.20394260e-01, -1.31325556e-01,  1.85816985e-01,\n",
       "         -1.85182350e-02,  2.25024109e-01, -3.45609857e-01,\n",
       "         -2.67502299e-01, -4.78094152e-01,  1.06224685e-01,\n",
       "         -4.23216328e-01, -4.66235026e-01, -6.68038559e-02],\n",
       "        [ 3.86866354e-01, -1.94724549e-02,  1.88559818e-01,\n",
       "          1.70705568e-02,  1.34607711e-01,  2.04120379e-01,\n",
       "         -1.56313223e-01, -1.15147124e-01,  4.21933660e-01,\n",
       "          4.15238488e-01, -3.61004144e-01, -1.46121080e-01],\n",
       "        [-1.73769595e-01, -2.75396031e-02,  1.58991116e-01,\n",
       "         -1.40250702e-01, -4.78720671e-01,  2.72127240e-01,\n",
       "          1.88318658e-01, -2.54424179e-01, -2.38341015e-02,\n",
       "         -3.72746550e-01, -4.12118786e-01, -4.50083863e-01],\n",
       "        [ 1.03477949e-01, -4.99265468e-01, -3.44709908e-01,\n",
       "         -4.62695540e-01, -1.04079336e-01,  3.08480188e-02,\n",
       "          3.78063829e-01,  6.93934006e-03, -4.78943662e-01,\n",
       "         -1.41959409e-01, -1.19333706e-01,  3.08804594e-01],\n",
       "        [-3.10482708e-01,  7.31659482e-02,  1.01411303e-01,\n",
       "         -1.09117963e-01, -4.59708512e-01,  4.37443367e-01,\n",
       "         -1.24667479e-01,  6.92044546e-02, -2.48399234e-01,\n",
       "         -4.66190482e-02,  1.20258076e-01,  1.29122729e-01],\n",
       "        [ 4.55071388e-01, -4.83291965e-02,  1.95838056e-01,\n",
       "          4.38884183e-01,  2.44727310e-02,  2.54502585e-01,\n",
       "          1.45322907e-01,  3.70065715e-01,  1.13614688e-01,\n",
       "         -4.52933970e-01, -3.63861124e-01, -4.09745655e-01],\n",
       "        [ 2.56054501e-01, -8.95642493e-02,  1.29726343e-01,\n",
       "          1.50712734e-01, -3.14944392e-01,  2.03385953e-02,\n",
       "         -1.16040589e-01, -1.56676473e-01, -1.71396089e-01,\n",
       "         -9.30191110e-02,  4.24737440e-02, -5.82949523e-02],\n",
       "        [-1.14224768e-01, -4.10009241e-01,  3.21669296e-01,\n",
       "         -3.53669608e-02,  1.59588791e-01,  1.94312122e-06,\n",
       "         -4.88364957e-01,  1.28507569e-01, -1.08280416e-01,\n",
       "          7.11121244e-02,  4.82465877e-01, -4.59777961e-01]])>,\n",
       " <tf.Tensor: id=13413, shape=(12,), dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " <tf.Tensor: id=13418, shape=(12, 5), dtype=float64, numpy=\n",
       " array([[ 0.06211771,  0.24966451, -0.01384237,  0.29369079,  0.34847106],\n",
       "        [-0.13295887, -0.25428574, -0.2364476 ,  0.28675198, -0.51559414],\n",
       "        [-0.5098628 , -0.38208599,  0.58475659, -0.44271429,  0.30056212],\n",
       "        [-0.34749573,  0.4529608 , -0.22908164,  0.03541686,  0.07675425],\n",
       "        [ 0.32233636,  0.3106129 ,  0.06146236,  0.19909685, -0.34352236],\n",
       "        [-0.24038357,  0.16164147, -0.15644609,  0.54084766, -0.22659195],\n",
       "        [-0.28698525, -0.28273317,  0.48396617,  0.16013297, -0.05440218],\n",
       "        [ 0.16236665, -0.28364672,  0.1025368 ,  0.2282006 ,  0.166199  ],\n",
       "        [-0.21703716, -0.26668283,  0.18739874, -0.00622303, -0.17755259],\n",
       "        [-0.15040402,  0.55648705, -0.15365776, -0.35344297, -0.57115752],\n",
       "        [ 0.09626045, -0.00530424, -0.2144136 ,  0.34795718,  0.22773678],\n",
       "        [ 0.30770702,  0.4671781 , -0.33072523,  0.23828401,  0.42753808]])>,\n",
       " <tf.Tensor: id=13423, shape=(5,), dtype=float64, numpy=array([0., 0., 0., 0., 0.])>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [x,y,z]\n",
    "\n",
    "\n",
    "\n",
    "[np.sum(w)/len(w) for w in zip(*l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import time\n",
    "import pybullet\n",
    "import reach2D\n",
    "from SAC import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (cell_name, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"cell_name\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mlp_gail_discriminator(Model):\n",
    "\n",
    "  def __init__(self, hidden_sizes=[32,32,32], activation = 'relu'):\n",
    "    super(mlp_gail_discriminator, self).__init__()\n",
    "    self.mlp = mlp(list(hidden_sizes), activation, activation)\n",
    "    self.prob = Dense(1, activation='sigmoid')\n",
    "\n",
    "\n",
    "  def call(self, obs, acts):\n",
    "    x = tf.concat([obs,acts], axis = -1)\n",
    "    x = self.mlp(x)\n",
    "    prob = self.prob(x)\n",
    "    return prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_train_step(batch, expert_batch,  discriminator, discriminator_optimizer):\n",
    "    batch_obs, batch_acts = batch['obs1'], batch['acts']\n",
    "    batch_expert_obs, batch_expert_acts = expert_batch['obs'], expert_batch['acts']\n",
    "    with tf.GradientTape() as tape:\n",
    "        # We'd like to maximise the log probability of the expert actions, and minmise log prob of generated actions.\n",
    "        expert_probs = discriminator(batch_expert_obs,batch_expert_acts)\n",
    "        # in ML, we take gradient to minimise, therefore minimise negative log probability \n",
    "        expert_loss = -tf.math.log(expert_probs)\n",
    "        agent_probs = discriminator(batch_obs,batch_acts)\n",
    "        # i.e, minimise -log(1-prob_generated_is_true)\n",
    "        agent_loss = -(tf.math.log(1-agent_probs))\n",
    "        # and thus, the reward our SAC agent gets will be -(tf.math.log(1-agent_probs)), it is trying to maximise this, \n",
    "        # discriminator is trying to mimise it.\n",
    "        loss = tf.reduce_sum(expert_loss + agent_loss)\n",
    "        expert_accuracy = tf.reduce_mean(tf.cast(expert_probs > 0.5, tf.float32))\n",
    "        agent_accuracy  = tf.reduce_mean(tf.cast(agent_probs < 0.5, tf.float32))\n",
    "\n",
    "\n",
    "        \n",
    "    gradients = tape.gradient(loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
    "    return loss.numpy(), expert_accuracy.numpy(), agent_accuracy.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_obs = np.load('collected_data/expert_obs_Pendulum-v0_Hidden_32l_25000.npy')\n",
    "expert_acts = np.load('collected_data/expert_actions_Pendulum-v0_Hidden_32l_25000.npy')\n",
    "\n",
    "def sample_expert_transitions(batch_size):\n",
    "    idxs = np.random.randint(0, len(expert_obs), size=batch_size)\n",
    "    return {'obs':expert_obs[idxs], 'acts':expert_acts[idxs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gail_run(discrim_req_acc):\n",
    "    ENV_NAME='Pendulum-v0'\n",
    "    env_fn = lambda : gym.make(ENV_NAME)\n",
    "    hid =128\n",
    "    l=2\n",
    "    gamma=0.999\n",
    "    steps_per_epoch=5000\n",
    "    seed=0\n",
    "    epochs=7\n",
    "    max_ep_len = 200 # for reacher, 1000 for not. \n",
    "    exp_name = ENV_NAME+'_Hidden_'+str(hid)+'l_'+str(l)\n",
    "    alpha=0.2\n",
    "    batch_size=100\n",
    "    lr=1e-3\n",
    "    start_steps=5000 \n",
    "    save_freq=1\n",
    "    load = False\n",
    "    render = False\n",
    "    polyak=0.995\n",
    "    replay_size=int(1e6)\n",
    "    ac_kwargs = {}\n",
    "    ac_kwargs['hidden_sizes'] = [hid]*l\n",
    "    discrim_req_acc = discrim_req_acc\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    env, test_env = env_fn(), env_fn()\n",
    "    # Get Env dimensions\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    SAC = SAC_model(env, obs_dim, act_dim, ac_kwargs['hidden_sizes'],lr, gamma, alpha, polyak,  load, exp_name)\n",
    "    # Experience buffer\n",
    "    replay_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=replay_size)\n",
    "\n",
    "    #Logging \n",
    "    start_time = time.time()\n",
    "    train_log_dir = 'logs/' + str(discrim_req_acc)+exp_name+':'+str(start_time)\n",
    "    summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "    discriminator = mlp_gail_discriminator()\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    def update_models(model, replay_buffer, steps, batch_size):\n",
    "        agent_accuracy = 0\n",
    "        # until the discriminator is trained to sufficiently distinguish correct transitions.\n",
    "        print('Updating Discriminator')\n",
    "        while agent_accuracy < discrim_req_acc or expert_acurracy < discrim_req_acc:\n",
    "            batch = replay_buffer.sample_batch(batch_size)\n",
    "            expert_batch = sample_expert_transitions(batch_size)\n",
    "            _,expert_acurracy,agent_accuracy = discriminator_train_step(batch, expert_batch, discriminator, discriminator_optimizer)\n",
    "            print(expert_acurracy, agent_accuracy)\n",
    "\n",
    "        # now update SAC\n",
    "        print('Updating Policy')\n",
    "        for j in range(steps):\n",
    "            batch = replay_buffer.sample_batch(batch_size)\n",
    "            batch_obs, batch_acts = batch['obs1'], batch['acts']\n",
    "            agent_probs = discriminator(batch_obs,batch_acts)\n",
    "            agent_reward = -(tf.math.log(1-agent_probs)).numpy().squeeze().astype('float32')\n",
    "            # use GAIL reward instead of environment reward\n",
    "            batch['rews'] = agent_reward\n",
    "\n",
    "            LossPi, LossQ1, LossQ2, LossV, Q1Vals, Q2Vals, VVals, LogPi = model.train_step(batch)\n",
    "\n",
    "\n",
    "    # now collect epsiodes\n",
    "    total_steps = steps_per_epoch * epochs\n",
    "    steps_collected = 0\n",
    "\n",
    "    # collect some initial random steps to initialise\n",
    "    random_steps = 5000\n",
    "    steps_collected  += rollout_trajectories(n_steps = random_steps,env = env, max_ep_len = max_ep_len, actor = 'random', replay_buffer = replay_buffer, summary_writer = summary_writer)\n",
    "\n",
    "\n",
    "    update_models(SAC, replay_buffer, steps = random_steps, batch_size = batch_size)\n",
    "\n",
    "    # now act with our actor, and alternately collect data, then train.\n",
    "    while steps_collected < total_steps:\n",
    "    # collect an episode\n",
    "        steps_collected  += rollout_trajectories(n_steps = max_ep_len,env = env, max_ep_len = max_ep_len, actor = SAC.get_action, replay_buffer = replay_buffer, summary_writer=summary_writer, current_total_steps = steps_collected)\n",
    "        # take than many training steps\n",
    "        update_models(SAC, replay_buffer, steps = max_ep_len, batch_size = batch_size)\n",
    "\n",
    "        # if an epoch has elapsed, save and test.\n",
    "        if steps_collected  > 0 and steps_collected  % steps_per_epoch == 0:\n",
    "            #SAC.save_weights()\n",
    "            # Test the performance of the deterministic version of the agent.\n",
    "            rollout_trajectories(n_steps = max_ep_len*10,env = test_env, max_ep_len = max_ep_len, actor = SAC.get_deterministic_action, summary_writer=summary_writer, current_total_steps = steps_collected, train = False, render = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_accs = [0.6, 0.7, 0.8, 0.9]\n",
    "for a in test_accs:\n",
    "    gail_run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok 5\n",
      "cu 78\n"
     ]
    }
   ],
   "source": [
    "d = {'ok':5, 'cu':78}\n",
    "for k,v in d.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ok 5\n",
      "1 cu 78\n"
     ]
    }
   ],
   "source": [
    "for i, (k,v) in enumerate(d.items()):\n",
    "    print(i,k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Okay, we need to do two ablations.\n",
    "# Whats the optimal accuracy that we want our discriminator to have before we train? It'll be different on every problem\n",
    "# but lets see if changing it on this simple problem can give us some ideas of what will happen.\n",
    "\n",
    "# How "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "expert_batch = sample_expert_transitions(batch_size)\n",
    "batch_expert_obs, batch_expert_acts = expert_batch['obs'], expert_batch['acts']\n",
    "expert_probs = discriminator(batch_expert_obs,batch_expert_acts)\n",
    "\n",
    "\n",
    "agent_reward = -(tf.math.log(1-expert_probs)).numpy().squeeze().astype('float32')\n",
    "agent_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator = mlp_gail_discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-(tf.math.log(0.0)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-(tf.math.log(1-0.01)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xs = np.linspace(0,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return -(tf.math.log(1-x+1e-8)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [f(x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    return (tf.math.log(x+1e-8)-(tf.math.log(1-x+1e-8)).numpy())\n",
    "ys = [f2(x) for x in xs]\n",
    "plt.plot(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    return tf.math.log(x+1e-8).numpy()\n",
    "ys = [f3(x) for x in xs]\n",
    "plt.plot(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(1,100,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.delete(x, [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.ones((100,1))\n",
    "a = a.numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q[.shapeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([11,21,31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5 % 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.tensor([np.ones(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
