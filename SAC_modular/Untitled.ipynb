{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-04 14:20:54,461\tWARNING worker.py:1373 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-09-04 14:20:54,463\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-09-04_14-20-54_462374_74501/logs.\n",
      "2019-09-04 14:20:54,572\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:45234 to respond...\n",
      "2019-09-04 14:20:54,795\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:28325 to respond...\n",
      "2019-09-04 14:20:54,801\tINFO services.py:809 -- Starting Redis shard with 3.44 GB max memory.\n",
      "2019-09-04 14:20:54,816\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-09-04_14-20-54_462374_74501/logs.\n",
      "2019-09-04 14:20:54,817\tWARNING services.py:1330 -- WARNING: The default object store size of 5.15 GB will use more than 50% of the available memory on this node (9.52 GB). Consider setting the object store memory manually to a smaller size to avoid memory contention with other applications.\n",
      "2019-09-04 14:20:54,818\tINFO services.py:1475 -- Starting the Plasma object store with 5.15 GB memory using /tmp.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.16.51.224',\n",
       " 'redis_address': '10.16.51.224:45234',\n",
       " 'object_store_address': '/tmp/ray/session_2019-09-04_14-20-54_462374_74501/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-09-04_14-20-54_462374_74501/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2019-09-04_14-20-54_462374_74501'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "import gym\n",
    "import numpy as np\n",
    "import psutil\n",
    "import scipy.signal\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "\n",
    "ray.init(num_cpus=num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def f(image, random_filter):\n",
    "    # Do some image processing.\n",
    "    return scipy.signal.convolve2d(image, random_filter)[::5, ::5]\n",
    "\n",
    "filters = [np.random.normal(size=(4, 4)) for _ in range(num_cpus)]\n",
    "\n",
    "# Time the code below.\n",
    "def test():\n",
    "    for _ in range(10):\n",
    "        image = np.zeros((3000, 3000))\n",
    "        image_id = ray.put(image)\n",
    "        ray.get([f.remote(image_id, filters[i]) for i in range(num_cpus)])\n",
    "        \n",
    "%time test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import psutil\n",
    "import scipy.signal\n",
    "\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "\n",
    "def f(args):\n",
    "    image, random_filter = args\n",
    "    # Do some image processing.\n",
    "    return scipy.signal.convolve2d(image, random_filter)[::5, ::5]\n",
    "\n",
    "pool = Pool(num_cpus)\n",
    "\n",
    "filters = [np.random.normal(size=(4, 4)) for _ in range(num_cpus)]\n",
    "\n",
    "# Time the code below.\n",
    "\n",
    "def test():\n",
    "    for _ in range(10):\n",
    "        image = np.zeros((3000, 3000))\n",
    "        pool.map(f, zip(num_cpus * [image], filters))\n",
    "%time test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import time\n",
    "import pybullet\n",
    "import reach2D\n",
    "from SAC import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mlp_gail_discriminator(Model):\n",
    "\n",
    "  def __init__(self, hidden_sizes=[32,32,32], activation = 'relu'):\n",
    "    super(mlp_gail_discriminator, self).__init__()\n",
    "    self.mlp = mlp(list(hidden_sizes), activation, activation)\n",
    "    self.prob = Dense(1, activation='sigmoid')\n",
    "\n",
    "\n",
    "  def call(self, obs, acts):\n",
    "    x = tf.concat([obs,acts], axis = -1)\n",
    "    x = self.mlp(x)\n",
    "    prob = self.prob(x)\n",
    "    return prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_train_step(batch, expert_batch,  discriminator, discriminator_optimizer):\n",
    "    batch_obs, batch_acts = batch['obs1'], batch['acts']\n",
    "    batch_expert_obs, batch_expert_acts = expert_batch['obs'], expert_batch['acts']\n",
    "    with tf.GradientTape() as tape:\n",
    "        # We'd like to maximise the log probability of the expert actions, and minmise log prob of generated actions.\n",
    "        expert_probs = discriminator(batch_expert_obs,batch_expert_acts)\n",
    "        # in ML, we take gradient to minimise, therefore minimise negative log probability \n",
    "        expert_loss = -tf.math.log(expert_probs)\n",
    "        agent_probs = discriminator(batch_obs,batch_acts)\n",
    "        # i.e, minimise -log(1-prob_generated_is_true)\n",
    "        agent_loss = -(tf.math.log(1-agent_probs))\n",
    "        # and thus, the reward our SAC agent gets will be -(tf.math.log(1-agent_probs)), it is trying to maximise this, \n",
    "        # discriminator is trying to mimise it.\n",
    "        loss = tf.reduce_sum(expert_loss + agent_loss)\n",
    "        expert_accuracy = tf.reduce_mean(tf.cast(expert_probs > 0.5, tf.float32))\n",
    "        agent_accuracy  = tf.reduce_mean(tf.cast(agent_probs < 0.5, tf.float32))\n",
    "\n",
    "\n",
    "        \n",
    "    gradients = tape.gradient(loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
    "    return loss.numpy(), expert_accuracy.numpy(), agent_accuracy.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_obs = np.load('collected_data/expert_obs_Pendulum-v0_Hidden_32l_25000.npy')\n",
    "expert_acts = np.load('collected_data/expert_actions_Pendulum-v0_Hidden_32l_25000.npy')\n",
    "\n",
    "def sample_expert_transitions(batch_size):\n",
    "    idxs = np.random.randint(0, len(expert_obs), size=batch_size)\n",
    "    return {'obs':expert_obs[idxs], 'acts':expert_acts[idxs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gail_run(discrim_req_acc):\n",
    "    ENV_NAME='Pendulum-v0'\n",
    "    env_fn = lambda : gym.make(ENV_NAME)\n",
    "    hid =128\n",
    "    l=2\n",
    "    gamma=0.999\n",
    "    steps_per_epoch=5000\n",
    "    seed=0\n",
    "    epochs=7\n",
    "    max_ep_len = 200 # for reacher, 1000 for not. \n",
    "    exp_name = ENV_NAME+'_Hidden_'+str(hid)+'l_'+str(l)\n",
    "    alpha=0.2\n",
    "    batch_size=100\n",
    "    lr=1e-3\n",
    "    start_steps=5000 \n",
    "    save_freq=1\n",
    "    load = False\n",
    "    render = False\n",
    "    polyak=0.995\n",
    "    replay_size=int(1e6)\n",
    "    ac_kwargs = {}\n",
    "    ac_kwargs['hidden_sizes'] = [hid]*l\n",
    "    discrim_req_acc = discrim_req_acc\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    env, test_env = env_fn(), env_fn()\n",
    "    # Get Env dimensions\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    SAC = SAC_model(env, obs_dim, act_dim, ac_kwargs['hidden_sizes'],lr, gamma, alpha, polyak,  load, exp_name)\n",
    "    # Experience buffer\n",
    "    replay_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=replay_size)\n",
    "\n",
    "    #Logging \n",
    "    start_time = time.time()\n",
    "    train_log_dir = 'logs/' + str(discrim_req_acc)+exp_name+':'+str(start_time)\n",
    "    summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "    discriminator = mlp_gail_discriminator()\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    def update_models(model, replay_buffer, steps, batch_size):\n",
    "        agent_accuracy = 0\n",
    "        # until the discriminator is trained to sufficiently distinguish correct transitions.\n",
    "        print('Updating Discriminator')\n",
    "        while agent_accuracy < discrim_req_acc or expert_acurracy < discrim_req_acc:\n",
    "            batch = replay_buffer.sample_batch(batch_size)\n",
    "            expert_batch = sample_expert_transitions(batch_size)\n",
    "            _,expert_acurracy,agent_accuracy = discriminator_train_step(batch, expert_batch, discriminator, discriminator_optimizer)\n",
    "            print(expert_acurracy, agent_accuracy)\n",
    "\n",
    "        # now update SAC\n",
    "        print('Updating Policy')\n",
    "        for j in range(steps):\n",
    "            batch = replay_buffer.sample_batch(batch_size)\n",
    "            batch_obs, batch_acts = batch['obs1'], batch['acts']\n",
    "            agent_probs = discriminator(batch_obs,batch_acts)\n",
    "            agent_reward = -(tf.math.log(1-agent_probs)).numpy().squeeze().astype('float32')\n",
    "            # use GAIL reward instead of environment reward\n",
    "            batch['rews'] = agent_reward\n",
    "\n",
    "            LossPi, LossQ1, LossQ2, LossV, Q1Vals, Q2Vals, VVals, LogPi = model.train_step(batch)\n",
    "\n",
    "\n",
    "    # now collect epsiodes\n",
    "    total_steps = steps_per_epoch * epochs\n",
    "    steps_collected = 0\n",
    "\n",
    "    # collect some initial random steps to initialise\n",
    "    random_steps = 5000\n",
    "    steps_collected  += rollout_trajectories(n_steps = random_steps,env = env, max_ep_len = max_ep_len, actor = 'random', replay_buffer = replay_buffer, summary_writer = summary_writer)\n",
    "\n",
    "\n",
    "    update_models(SAC, replay_buffer, steps = random_steps, batch_size = batch_size)\n",
    "\n",
    "    # now act with our actor, and alternately collect data, then train.\n",
    "    while steps_collected < total_steps:\n",
    "    # collect an episode\n",
    "        steps_collected  += rollout_trajectories(n_steps = max_ep_len,env = env, max_ep_len = max_ep_len, actor = SAC.get_action, replay_buffer = replay_buffer, summary_writer=summary_writer, current_total_steps = steps_collected)\n",
    "        # take than many training steps\n",
    "        update_models(SAC, replay_buffer, steps = max_ep_len, batch_size = batch_size)\n",
    "\n",
    "        # if an epoch has elapsed, save and test.\n",
    "        if steps_collected  > 0 and steps_collected  % steps_per_epoch == 0:\n",
    "            #SAC.save_weights()\n",
    "            # Test the performance of the deterministic version of the agent.\n",
    "            rollout_trajectories(n_steps = max_ep_len*10,env = test_env, max_ep_len = max_ep_len, actor = SAC.get_deterministic_action, summary_writer=summary_writer, current_total_steps = steps_collected, train = False, render = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_accs = [0.6, 0.7, 0.8, 0.9]\n",
    "for a in test_accs:\n",
    "    gail_run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Okay, we need to do two ablations.\n",
    "# Whats the optimal accuracy that we want our discriminator to have before we train? It'll be different on every problem\n",
    "# but lets see if changing it on this simple problem can give us some ideas of what will happen.\n",
    "\n",
    "# How "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "expert_batch = sample_expert_transitions(batch_size)\n",
    "batch_expert_obs, batch_expert_acts = expert_batch['obs'], expert_batch['acts']\n",
    "expert_probs = discriminator(batch_expert_obs,batch_expert_acts)\n",
    "\n",
    "\n",
    "agent_reward = -(tf.math.log(1-expert_probs)).numpy().squeeze().astype('float32')\n",
    "agent_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator = mlp_gail_discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-(tf.math.log(0.0)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-(tf.math.log(1-0.01)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xs = np.linspace(0,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return -(tf.math.log(1-x+1e-8)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [f(x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    return (tf.math.log(x+1e-8)-(tf.math.log(1-x+1e-8)).numpy())\n",
    "ys = [f2(x) for x in xs]\n",
    "plt.plot(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    return tf.math.log(x+1e-8).numpy()\n",
    "ys = [f3(x) for x in xs]\n",
    "plt.plot(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(1,100,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.delete(x, [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.ones((100,1))\n",
    "a = a.numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = np.where(a < 2)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q[.shapeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([11,21,31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5 % 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.tensor([np.ones(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
